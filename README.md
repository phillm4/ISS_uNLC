## Instrument Shaft Segmentation using Unsupervised Non-Local Consensus Voting.

Application of the methods explored in the 2017 paper, [Learning Features by Watching Objects Move](https://people.eecs.berkeley.edu/~pathak/unsupervised_video/). More specifically, it is an evaluation of the unsupervised bottom-up video motion segmentation algorithm, [uNLC]( https://github.com/pathak22/videoseg), explained in section 5.1 of the paper, on robotic surgery images and the ability to generate pseudo ground truth data for instrument shaft segmentation. As noted by the authors of Learning Features by Watching Objects Move, uNLC is in fact an implementation of Faktor and Iraniâ€™s NLC algorithm from their 2014 paper, [Video Segmentation by Non-Local Consensus Voting]( http://www.wisdom.weizmann.ac.il/~vision/NonLocalVideoSegmentation.html). 
